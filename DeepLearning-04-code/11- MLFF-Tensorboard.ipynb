{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> <div align=\"center\">In the name of God </div></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Author: Sayed Kamaledin Ghiasi-Shrirazi</font> <a href=\"http://profsite.um.ac.ir/~k.ghiasi\">(http://profsite.um.ac.ir/~k.ghiasi)</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A multi-layer feedforward neural network in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing general modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing PyTorch modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from   torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the MLFF network by inheriting from nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the following command is crucial:\n",
    "\n",
    "``\n",
    "self.layers = nn.ModuleList(layersList)\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLFF(nn.Module):\n",
    "    def __init__(self, num_hidden_layers, num_input_neurons, \n",
    "                 num_hidden_neurons, num_output_neurons):\n",
    "        super().__init__()\n",
    "        self.layersCount =  num_hidden_layers+1\n",
    "        layersList = [None] * (self.layersCount)\n",
    "        layersList[0] = nn.Linear(num_input_neurons, num_hidden_neurons)\n",
    "        for i in range (1, num_hidden_layers):\n",
    "            layersList[i] = nn.Linear(num_hidden_neurons, num_hidden_neurons)\n",
    "        layersList[num_hidden_layers] = nn.Linear(num_hidden_neurons, num_output_neurons)\n",
    "        self.layers  = nn.ModuleList(layersList)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(self.layersCount):\n",
    "            x = self.layers[i](x)\n",
    "            if (i < self.layersCount - 1):\n",
    "                pass\n",
    "                #x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLFF(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = MLFF(5, 784, 100, 10)\n",
    "print (net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MnistTrainX = sio.loadmat ('../../datasets/mnist/MnistTrainX')['MnistTrainX'] / 255;\n",
    "MnistTrainY = sio.loadmat ('../../datasets/mnist/MnistTrainY')['MnistTrainY'];\n",
    "MnistTestX  = sio.loadmat ('../../datasets/mnist/MnistTestX')['MnistTestX'] / 255;\n",
    "MnistTestY  = sio.loadmat ('../../datasets/mnist/MnistTestY')['MnistTestY'];\n",
    "\n",
    "N = 60000\n",
    "MnistTrainX = MnistTrainX[:N,:]\n",
    "MnistTrainY = MnistTrainY[:N,:]\n",
    "XTrain = MnistTrainX\n",
    "yTrain = MnistTrainY.squeeze()\n",
    "XTest = MnistTestX\n",
    "yTest = MnistTestY.squeeze()\n",
    "N, dim = XTrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "report_after_X_iterations = 100\n",
    "learning_rate = 0.1\n",
    "num_batches = N // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- iteration #0 of 600 at epoch #0 of 2 ---- :\n",
      "Loss = 0.11023735255002975, Accuracy on training data = 89.53999999999999%\n",
      "0\n",
      "\n",
      "---- iteration #100 of 600 at epoch #0 of 2 ---- :\n",
      "Loss = 0.32644739747047424, Accuracy on training data = 91.48333333333333%\n",
      "100\n",
      "\n",
      "---- iteration #200 of 600 at epoch #0 of 2 ---- :\n",
      "Loss = 0.3714450001716614, Accuracy on training data = 90.565%\n",
      "200\n",
      "\n",
      "---- iteration #300 of 600 at epoch #0 of 2 ---- :\n",
      "Loss = 0.25609225034713745, Accuracy on training data = 90.76666666666667%\n",
      "300\n",
      "\n",
      "---- iteration #400 of 600 at epoch #0 of 2 ---- :\n",
      "Loss = 0.32117268443107605, Accuracy on training data = 91.62%\n",
      "400\n",
      "\n",
      "---- iteration #500 of 600 at epoch #0 of 2 ---- :\n",
      "Loss = 0.35292351245880127, Accuracy on training data = 91.21166666666667%\n",
      "500\n",
      "\n",
      "---- iteration #0 of 600 at epoch #1 of 2 ---- :\n",
      "Loss = 0.17817768454551697, Accuracy on training data = 90.34%\n",
      "600\n",
      "\n",
      "---- iteration #100 of 600 at epoch #1 of 2 ---- :\n",
      "Loss = 0.3193376362323761, Accuracy on training data = 91.63333333333334%\n",
      "700\n",
      "\n",
      "---- iteration #200 of 600 at epoch #1 of 2 ---- :\n",
      "Loss = 0.3596145510673523, Accuracy on training data = 90.88833333333334%\n",
      "800\n",
      "\n",
      "---- iteration #300 of 600 at epoch #1 of 2 ---- :\n",
      "Loss = 0.25215214490890503, Accuracy on training data = 90.95166666666667%\n",
      "900\n",
      "\n",
      "---- iteration #400 of 600 at epoch #1 of 2 ---- :\n",
      "Loss = 0.31092777848243713, Accuracy on training data = 91.71666666666667%\n",
      "1000\n",
      "\n",
      "---- iteration #500 of 600 at epoch #1 of 2 ---- :\n",
      "Loss = 0.34600308537483215, Accuracy on training data = 91.35166666666666%\n",
      "1100\n"
     ]
    }
   ],
   "source": [
    "net.to(device)\n",
    "\n",
    "tensorboard_comment = 'MLFF'\n",
    "tb = SummaryWriter(log_dir = 'runs', comment = tensorboard_comment)\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr= learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range (num_epochs):\n",
    "    for itr in range (num_batches):\n",
    "        X = torch.tensor (MnistTrainX[itr*batch_size:(itr+1)*batch_size,:], dtype=torch.float)\n",
    "        T = MnistTrainY[itr*batch_size:(itr+1)*batch_size]\n",
    "        T = torch.tensor (T.squeeze(), dtype = torch.long)\n",
    "        X = X.to(device)\n",
    "        T = T.to(device)\n",
    "        if epoch == 0 and itr == 0:\n",
    "            tb.add_graph (net, X)        \n",
    "        output = net(X)\n",
    "        loss = criterion(output, T)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (itr % report_after_X_iterations == 0):\n",
    "            print('\\n---- iteration #{0} of {1} at epoch #{2} of {3} ---- :'.format(\n",
    "                itr, num_batches, epoch, num_epochs))\n",
    "            score = 0.0\n",
    "            for i in range(num_batches):\n",
    "                X = MnistTrainX[i * batch_size:(i + 1) * batch_size, :]\n",
    "                T = MnistTrainY[i * batch_size:(i + 1) * batch_size]\n",
    "                T = T.squeeze()\n",
    "                X = torch.tensor(X, dtype=torch.float).to(device)\n",
    "                #T = torch.tensor(T, dtype=torch.long).to(device)\n",
    "                output = net(X)\n",
    "                prediction = torch.argmax(output, dim=1).cpu().numpy()\n",
    "                score += np.sum(prediction == T)\n",
    "            score /= N\n",
    "            score *= 100\n",
    "            print('Loss = {0}, Accuracy on training data = {1}%'.format(loss.item(), score))\n",
    "            total_itr = epoch * num_batches + itr\n",
    "            print (total_itr)\n",
    "            tb.add_scalar ('Training score', scalar_value= score, global_step = total_itr)\n",
    "            tb.add_scalar ('Training loss', scalar_value=loss, global_step = total_itr)\n",
    "            data = net.layers[0].weight[0,:].detach().cpu().numpy()\n",
    "            data_pos = np.maximum(data,0)\n",
    "            data_neg = np.maximum(-data,0)\n",
    "            max_val = np.maximum (np.max(data_pos), np.max(data_neg))\n",
    "            data_pos /= max_val\n",
    "            data_neg /= max_val\n",
    "            img = np.zeros ([3,28,28])\n",
    "            img[0,:,:] = np.reshape (data_pos, [28,28])\n",
    "            img[1,:,:] = np.reshape (data_neg, [28,28])\n",
    "            tb.add_image  ('Layer1Visualization', img, global_step = total_itr)\n",
    "            for i,layer in enumerate (net.layers):\n",
    "                tb.add_histogram (f'layer{i}.weight', net.layers[i].weight, global_step = total_itr)\n",
    "\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.29613201e-02,  2.52459645e-02, -2.86724027e-02,  3.42800468e-03,\n",
       "       -1.54972672e-02,  1.26734935e-02,  3.49265374e-02, -1.58633254e-02,\n",
       "       -1.52948759e-02,  2.25275755e-03,  2.91853063e-02,  9.53777507e-03,\n",
       "        3.21108066e-02,  2.92489794e-03,  1.48941884e-02,  3.07525545e-02,\n",
       "       -2.92217527e-02, -1.95769966e-02, -2.53907964e-02, -6.14722818e-03,\n",
       "       -1.38979983e-02,  9.36683267e-04,  3.07190977e-02, -8.10556114e-04,\n",
       "        1.22003891e-02, -3.24045382e-02, -3.31997201e-02,  8.14040005e-03,\n",
       "       -7.08421692e-03, -2.07496174e-02,  7.12541118e-03, -2.75545213e-02,\n",
       "       -5.00779366e-03, -1.74469538e-02,  1.64579898e-02, -3.53653952e-02,\n",
       "       -1.83401126e-02,  3.25091667e-02,  5.36939176e-03, -7.96594005e-03,\n",
       "       -3.80959660e-02, -1.78201532e-04,  3.20014134e-02,  1.35507493e-03,\n",
       "       -9.31689143e-03, -1.21201621e-02,  3.32228988e-02, -2.45643649e-02,\n",
       "       -2.07378231e-02,  3.34474333e-02, -3.30965519e-02, -3.38512771e-02,\n",
       "        3.10086198e-02,  4.36371192e-03,  1.16172358e-02, -2.87648626e-02,\n",
       "        1.36594325e-02, -2.57070661e-02,  2.17994414e-02,  1.31830452e-02,\n",
       "        1.36080198e-02, -3.32037471e-02, -3.43631245e-02,  1.53769841e-02,\n",
       "       -7.42505118e-03, -9.30423383e-03,  2.74629537e-02, -4.04787399e-02,\n",
       "       -4.42409888e-02, -1.55106522e-02, -1.06406966e-02,  2.61120107e-02,\n",
       "       -6.13568211e-03, -3.77449580e-02, -2.18175519e-02,  3.22657973e-02,\n",
       "       -1.78128015e-02,  1.79715008e-02, -1.54740093e-02, -2.73656566e-02,\n",
       "        3.41655798e-02,  2.11970173e-02, -1.64794084e-02,  8.63806903e-03,\n",
       "        2.88048498e-02, -4.70866077e-03, -3.13429609e-02,  2.44259331e-02,\n",
       "        2.80096717e-02,  2.60226075e-02, -2.60719880e-02, -2.93042958e-02,\n",
       "        2.21504979e-02, -2.97924522e-02, -2.71385461e-02, -1.01699242e-02,\n",
       "       -1.77571755e-02,  1.45464425e-03, -5.03753573e-02,  2.61962065e-03,\n",
       "       -2.87667122e-02, -3.25066559e-02, -2.67118011e-02,  2.87568215e-02,\n",
       "       -2.89409850e-02, -3.69572863e-02, -2.91286726e-02, -1.02393404e-02,\n",
       "        1.82933677e-02, -1.83557440e-02, -1.41901234e-02, -2.87083909e-03,\n",
       "        3.27086449e-03,  1.14218695e-02,  1.38458619e-02, -2.07005981e-02,\n",
       "       -4.29979060e-03,  2.70816106e-02,  1.91695604e-03,  2.58744303e-02,\n",
       "       -2.24261601e-02, -1.05645200e-02, -5.17538376e-03, -6.56675640e-03,\n",
       "       -2.20729373e-02, -1.95648856e-02, -3.07521969e-03, -5.72019257e-03,\n",
       "       -5.47278346e-03, -3.00631635e-02, -4.01180461e-02, -1.34981629e-02,\n",
       "       -2.68881139e-03, -4.26264072e-04,  1.15774926e-02,  1.80858001e-02,\n",
       "       -1.81517620e-02,  2.05674376e-02, -1.62085090e-02,  3.41939740e-02,\n",
       "       -1.64062213e-02, -2.69026756e-02,  3.38613689e-02,  3.37342359e-02,\n",
       "        9.16191004e-03,  1.38836633e-02,  7.10903807e-03,  3.09360605e-02,\n",
       "       -1.84651949e-02, -2.85985507e-02, -1.01335533e-02,  2.49362458e-03,\n",
       "       -1.80017315e-02, -2.82652155e-02,  4.56919335e-03, -2.53409911e-02,\n",
       "       -2.98846141e-02, -1.25163896e-02,  1.06917217e-03, -3.93307135e-02,\n",
       "       -5.87486140e-02, -2.42432747e-02,  2.73492895e-02, -7.61116575e-03,\n",
       "        2.75973398e-02, -2.51377542e-02,  1.89491734e-02, -3.31374332e-02,\n",
       "        4.82439995e-04,  7.21709244e-03,  2.62227431e-02, -1.17780203e-02,\n",
       "       -1.45282419e-02, -1.23543432e-02,  2.53207125e-02,  3.32402289e-02,\n",
       "        1.67869627e-02,  3.67174856e-02, -1.24023447e-03,  1.92730296e-02,\n",
       "       -3.85765475e-03, -2.46535018e-02,  3.08844801e-02,  1.94576774e-02,\n",
       "        9.30224359e-03,  2.55270768e-02,  4.15174663e-02, -1.24826478e-02,\n",
       "       -1.06978118e-02, -5.20171858e-02, -2.16579679e-02, -3.31098065e-02,\n",
       "       -8.24985001e-03,  8.15176126e-03,  1.08099659e-03,  2.69018230e-03,\n",
       "        1.27890762e-02,  1.67425536e-02,  3.07802148e-02,  1.00948932e-02,\n",
       "       -1.67256333e-02, -1.12997917e-02, -7.79212511e-04,  2.42988225e-02,\n",
       "       -3.66086960e-02, -1.72972381e-02, -3.03012189e-02,  2.57163886e-02,\n",
       "        3.80246304e-02,  5.99630140e-02, -2.25818413e-03,  3.15703116e-02,\n",
       "        3.76533754e-02,  3.65399979e-02,  2.47242264e-02, -5.78702707e-03,\n",
       "        2.23213844e-02,  1.99673101e-02, -5.51970713e-02, -1.10092117e-02,\n",
       "       -4.04238664e-02, -4.82903011e-02,  1.86120588e-02,  1.91600006e-02,\n",
       "       -2.96227019e-02, -1.47427740e-02,  3.05242185e-02,  2.75849532e-02,\n",
       "        2.49411520e-02, -9.64022614e-03, -1.81508139e-02, -3.59671586e-03,\n",
       "        3.33153233e-02, -3.61806713e-02, -1.21908467e-02, -2.91270725e-02,\n",
       "       -3.88438925e-02, -1.36706512e-02,  1.74214914e-02,  5.07587530e-02,\n",
       "       -3.11256200e-02, -6.53048919e-04, -1.25256497e-02, -2.38196813e-02,\n",
       "        4.37327521e-03, -1.14804264e-02,  3.59140453e-03, -1.26427617e-02,\n",
       "       -7.02025667e-02, -4.43847068e-02, -3.43646854e-02, -1.70946326e-02,\n",
       "        1.02968402e-02,  8.08458496e-03,  2.51024198e-02,  1.43419942e-02,\n",
       "       -1.78623293e-03, -2.06827782e-02,  1.84321851e-02, -2.51883250e-02,\n",
       "       -1.93388225e-03, -2.72592925e-03, -1.72419602e-03, -8.10258905e-04,\n",
       "       -2.60939845e-03,  1.02163674e-02,  4.65095378e-02,  2.89603304e-02,\n",
       "        3.35736275e-02, -1.56378094e-02, -6.15101680e-03, -9.14904661e-03,\n",
       "       -2.09338143e-02, -3.01137529e-02, -2.96185650e-02, -6.59335703e-02,\n",
       "       -7.63184130e-02, -6.23766705e-02, -4.78718095e-02, -2.83341855e-02,\n",
       "        7.11446861e-03,  3.15241218e-02,  3.42698395e-02,  4.76422533e-03,\n",
       "        2.14154683e-02,  3.42373014e-03, -1.94458030e-02,  2.00235173e-02,\n",
       "        2.02305848e-03, -4.47797403e-02, -2.66376287e-02, -1.39161656e-02,\n",
       "       -3.92085873e-02,  7.44484365e-04,  2.94757206e-02, -1.11096110e-02,\n",
       "        1.76323485e-02,  3.34867686e-02, -1.12000424e-02,  1.74284186e-02,\n",
       "        4.10691723e-02,  3.08389049e-02, -1.67348720e-02, -6.55283406e-02,\n",
       "       -1.09964401e-01, -8.10701102e-02,  2.27198144e-03, -2.74090767e-02,\n",
       "        7.02530798e-03, -1.99754629e-02,  3.90782468e-02, -1.22399079e-02,\n",
       "        2.13680938e-02, -3.31746824e-02,  6.31473400e-03,  2.32624868e-03,\n",
       "        1.05692232e-02,  2.72642430e-02, -8.39280803e-03,  1.34019814e-02,\n",
       "       -1.75459962e-02, -4.03115898e-02, -1.57474391e-02,  3.40826474e-02,\n",
       "        4.36308468e-03,  6.12408705e-02, -6.63565518e-03, -1.07756769e-02,\n",
       "        2.45601498e-02,  4.37784605e-02,  3.06097586e-02, -3.22083086e-02,\n",
       "       -3.82505655e-02, -2.21682265e-02,  1.03907203e-02,  1.77843357e-03,\n",
       "        3.50388661e-02, -6.92865439e-03,  3.02474443e-02,  3.35881449e-02,\n",
       "        2.18662955e-02,  4.18774560e-02,  3.34720053e-02,  3.87464762e-02,\n",
       "       -2.80832348e-04,  3.11833899e-02,  4.65683220e-03, -2.28145234e-02,\n",
       "       -3.66521552e-02, -1.37868244e-02, -1.52030149e-02,  2.40992717e-02,\n",
       "        3.13444659e-02,  2.37175412e-02,  7.32654855e-02, -7.77643593e-03,\n",
       "       -1.68603547e-02,  6.25470579e-02,  4.24605906e-02,  3.02285329e-02,\n",
       "        1.05845081e-02, -8.23332183e-03, -1.77141707e-02, -3.20625026e-04,\n",
       "       -2.02203877e-02,  8.85660481e-03, -1.32259764e-02,  1.60433073e-02,\n",
       "        3.28858085e-02,  4.12933938e-02,  2.32151896e-02, -7.16027163e-04,\n",
       "        4.24415991e-03, -1.46613849e-04, -8.99578817e-03, -5.84965460e-02,\n",
       "       -6.43322691e-02,  7.48739904e-03,  6.78241346e-03,  2.02074498e-02,\n",
       "        3.65115255e-02,  1.09787965e-02,  3.77659611e-02,  4.84144129e-02,\n",
       "       -1.63699985e-02,  3.48588005e-02,  2.85707600e-02,  1.03657125e-02,\n",
       "        2.60281400e-03,  1.02595016e-02, -2.23217644e-02, -2.59516644e-03,\n",
       "       -2.62738541e-02, -1.37048382e-02,  4.26948722e-03,  1.31445248e-02,\n",
       "        1.38464384e-02, -7.67479837e-03,  1.44102415e-02,  1.92756522e-02,\n",
       "        2.72383261e-03,  8.12914595e-03, -3.04846782e-02, -1.84901599e-02,\n",
       "        8.90770834e-03, -3.08810901e-02,  2.69021336e-02,  3.66102979e-02,\n",
       "        5.66132478e-02,  2.46096309e-02,  4.39383797e-02,  4.75819521e-02,\n",
       "        4.18759994e-02, -1.20290956e-02, -1.21777633e-03,  1.36501286e-02,\n",
       "       -2.73525398e-02,  4.17250954e-03,  8.17679614e-03, -1.99920852e-02,\n",
       "        1.96855087e-02, -3.38213407e-02, -2.58876849e-02,  4.11913637e-03,\n",
       "       -1.60037354e-02, -1.77669972e-02,  5.39322123e-02, -2.67287513e-04,\n",
       "        3.59823671e-03, -3.84090208e-02,  1.97909307e-02,  1.39347324e-03,\n",
       "       -1.28448568e-02,  2.00718939e-02, -1.96397007e-02,  1.21213114e-02,\n",
       "        1.01394299e-02,  4.61789668e-02,  1.38293235e-02,  3.71698327e-02,\n",
       "        6.99741114e-03,  4.40058671e-02,  4.98446636e-02, -1.69932619e-02,\n",
       "       -5.60657345e-02, -4.65399064e-02, -1.02952989e-02, -1.80578548e-02,\n",
       "       -2.52336431e-02,  1.10030000e-03, -3.26886028e-03,  8.31355713e-03,\n",
       "        1.06831323e-02,  1.80179719e-02, -2.12314725e-02, -1.78503487e-02,\n",
       "        3.94549519e-02,  2.57657599e-02, -7.25594070e-03, -1.93114467e-02,\n",
       "        1.87947396e-02, -8.20693839e-03,  1.54782096e-02,  2.67667416e-02,\n",
       "        3.10275145e-02,  4.04033922e-02, -9.69985686e-03, -5.59277274e-03,\n",
       "        4.37593609e-02, -2.19131149e-02, -3.81244272e-02, -5.85155226e-02,\n",
       "       -2.22311560e-02, -2.84945425e-02, -2.89105698e-02, -2.18245853e-02,\n",
       "        2.11074576e-02,  2.93775424e-02,  1.32591398e-02,  1.20108034e-02,\n",
       "       -2.85373293e-02, -3.44582275e-02, -5.76573052e-02, -1.12758847e-02,\n",
       "       -2.59893965e-02, -2.27869321e-02, -1.36519074e-02, -2.30711792e-02,\n",
       "        6.69854740e-03,  2.13164333e-02,  8.45323969e-03,  3.37112583e-02,\n",
       "        1.59682296e-02,  2.36046035e-02, -2.09474098e-02, -1.34964229e-03,\n",
       "       -4.01636027e-02,  8.07215367e-03, -1.16742738e-02, -1.66593771e-02,\n",
       "       -4.71512489e-02, -2.00515818e-02, -4.44651290e-04,  1.09434268e-02,\n",
       "        1.14002097e-02, -5.65467449e-03, -6.98667369e-04, -2.09572315e-02,\n",
       "       -1.90044404e-04, -5.49637079e-02, -2.70065982e-02, -4.92958203e-02,\n",
       "       -1.07288361e-02, -3.09870765e-02,  3.55422939e-03, -2.33870335e-02,\n",
       "        1.69766899e-02, -2.48036701e-02,  5.99628293e-05, -3.15887444e-02,\n",
       "       -1.31882969e-02,  9.81450733e-03,  4.13243398e-02,  7.70720001e-03,\n",
       "       -1.03670061e-02,  2.08783522e-02, -1.65566839e-02, -4.81228940e-02,\n",
       "       -8.01570527e-03, -3.47887957e-03,  2.37721670e-02, -3.33253265e-04,\n",
       "       -2.39334609e-02, -3.48057970e-02, -4.02244390e-04, -4.05641086e-02,\n",
       "       -4.23391536e-02, -1.18576325e-02, -1.64665673e-02, -3.70164737e-02,\n",
       "       -5.80314137e-02, -3.25954668e-02,  8.55200109e-04,  2.19067093e-03,\n",
       "       -7.06459675e-03,  1.55104408e-02,  1.61855649e-02,  2.70300498e-03,\n",
       "        3.60583477e-02, -3.17212082e-02,  1.32464124e-02,  4.16204194e-03,\n",
       "        2.36937609e-02,  4.96444060e-03, -2.91562639e-02, -3.67910601e-02,\n",
       "        2.19595083e-03,  2.41121813e-03, -2.99702436e-02, -2.16944888e-02,\n",
       "       -2.20597237e-02, -2.53635682e-02,  6.85700634e-03, -4.23874296e-02,\n",
       "       -1.13451323e-02, -4.01110053e-02, -6.40895516e-02, -4.56935726e-02,\n",
       "       -1.65490378e-02, -4.75341976e-02, -4.27396409e-02, -5.14715537e-02,\n",
       "       -5.18260933e-02,  1.08828507e-02,  1.26452064e-02,  1.78887844e-02,\n",
       "        6.80392515e-03, -4.70369644e-02, -2.29332186e-02, -7.56224198e-03,\n",
       "        5.09964162e-03,  1.02091429e-03, -2.92916987e-02, -5.14846481e-02,\n",
       "        1.26666995e-02, -3.73957269e-02,  2.40909923e-02,  8.25413689e-03,\n",
       "        2.88976054e-03, -2.88539585e-02, -2.20960695e-02, -1.47524020e-02,\n",
       "       -5.99745736e-02, -2.24415399e-02, -5.89172877e-02, -3.97621319e-02,\n",
       "       -3.62809114e-02, -2.11266149e-03, -4.64241914e-02, -2.11523827e-02,\n",
       "       -2.33311746e-02,  1.74315844e-03, -4.25929725e-02, -3.06508038e-02,\n",
       "       -1.39812035e-02, -3.73875424e-02, -1.52856177e-02,  7.10236654e-03,\n",
       "       -2.46343557e-02, -5.97740412e-02, -3.00089251e-02, -2.69400440e-02,\n",
       "       -1.17620248e-02,  2.22186185e-02,  6.30116137e-03, -3.50984782e-02,\n",
       "       -6.62450632e-03,  1.13979019e-02, -3.47901806e-02, -6.81422069e-04,\n",
       "       -6.54102443e-03, -3.65673192e-02, -6.32476574e-03, -8.66765808e-03,\n",
       "       -1.87156759e-02, -5.90379685e-02, -1.51257461e-03, -3.28911617e-02,\n",
       "        3.52068315e-03, -1.36260018e-02, -2.64787488e-02, -1.08765392e-02,\n",
       "        1.98477507e-02, -2.30560210e-02, -7.16501242e-03, -6.94354950e-03,\n",
       "       -3.14732976e-02, -1.82100646e-02, -5.81172295e-02,  7.53774401e-03,\n",
       "       -1.53649123e-02, -2.39286432e-03,  3.39686014e-02, -2.75863595e-02,\n",
       "        2.62717195e-02, -2.75906119e-02, -1.47570930e-02, -2.08523460e-02,\n",
       "       -1.28637264e-02,  2.41319258e-02,  1.94816925e-02,  5.87496022e-03,\n",
       "       -1.91349164e-02, -2.46603903e-03, -3.70604694e-02, -5.56260459e-02,\n",
       "       -1.65987667e-02, -3.49186659e-02, -5.28956717e-03, -2.50884034e-02,\n",
       "       -6.14129901e-02, -2.55915225e-02, -1.69356875e-02, -7.76177458e-03,\n",
       "       -2.67096516e-02,  2.05765683e-02,  6.78408099e-03, -3.13171633e-02,\n",
       "       -1.60815045e-02,  2.39837747e-02, -9.93852597e-03, -1.65357646e-02,\n",
       "        3.19440849e-02, -4.06302139e-03, -2.22647702e-03,  5.49736852e-03,\n",
       "        2.15570182e-02,  6.55439356e-03, -2.91568949e-03,  3.83512825e-02,\n",
       "       -1.82311051e-02, -2.50171986e-03, -1.70874242e-02,  1.62404664e-02,\n",
       "       -6.40723333e-02, -3.02835461e-03, -1.42297428e-02, -6.75097331e-02,\n",
       "       -4.70039397e-02,  2.44659111e-02,  4.94681345e-03, -3.11579313e-02,\n",
       "        1.32368952e-02,  8.88485694e-04, -1.76313110e-02, -1.03225186e-02,\n",
       "        2.57446175e-03,  7.31516024e-03, -3.03765405e-02,  2.51654051e-02,\n",
       "        2.20339261e-02, -1.51106846e-02,  1.40117295e-02,  2.03511654e-03,\n",
       "        1.09263125e-03,  2.67238114e-02,  1.66445337e-02,  1.74867604e-02,\n",
       "        3.16306390e-02,  1.52787194e-02, -1.41390087e-02, -1.50879966e-02,\n",
       "        4.97944327e-03,  3.31469029e-02, -1.98543649e-02,  9.23437905e-03,\n",
       "       -1.11828828e-02,  2.56676711e-02, -1.61353964e-02,  8.99372716e-03,\n",
       "       -8.54978338e-03,  1.78928506e-02,  9.17282596e-04,  1.70640834e-02,\n",
       "       -2.36036815e-02,  2.16818843e-02, -3.28105642e-03, -2.43523344e-03,\n",
       "       -2.67465208e-02,  2.55618654e-02, -1.07427668e-02, -2.61927359e-02,\n",
       "       -2.40866207e-02,  1.51626468e-02, -2.40647551e-02,  1.24806734e-02,\n",
       "       -7.95593020e-03,  3.61932293e-02,  1.70898326e-02,  3.71594843e-03,\n",
       "        1.63589492e-02,  6.65996969e-02,  3.03745158e-02,  2.11551283e-02,\n",
       "        5.39186075e-02,  5.59894778e-02,  1.17363567e-02,  2.06812155e-02,\n",
       "        2.94673201e-02,  1.17046665e-02, -2.19333805e-02, -1.85975630e-03,\n",
       "        1.43137267e-02,  6.53542113e-03, -1.29464399e-02,  1.35037303e-03,\n",
       "       -1.77191719e-02, -3.31302062e-02,  8.96692276e-03,  3.13670076e-02,\n",
       "       -1.52388792e-02,  1.43910246e-03, -3.45437527e-02, -3.00203934e-02,\n",
       "       -2.19033416e-02,  7.33170286e-03,  2.61550769e-02,  2.31354907e-02,\n",
       "        2.63611637e-02, -1.74294543e-02,  2.30947859e-03,  3.78221162e-02,\n",
       "        2.88131204e-03, -4.13457351e-03,  3.83400754e-03,  1.90391783e-02,\n",
       "        6.77292282e-03,  3.12444940e-02, -1.36631411e-02, -1.92168038e-02,\n",
       "       -1.28652379e-02,  2.48429999e-02,  2.83165388e-02,  1.56484693e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[0].weight[0,:].detach().cpu().numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
